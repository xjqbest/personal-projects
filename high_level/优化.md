

### cache友好

我们可以通过编程来充分利用cache性能，但是我们需要同时考虑数据的组织形式和数据的访问形式，此外，
可以使用分块处理的方式获得空间局部性更好的方法。获得最佳Cache性能是与平台相关的，比如，
Cache的大小，Cache行大小，以及映射策略。比较通用的法则当然是工作集越小越好，访问跨距越小越好。

一段Cache友好代码往往运行速度较快。但我们需要注意以下两点：
 - 尽可能多的重复使用一个数据（时间局限性）【如果我们需要在某个任务多次使用一个数据时，应该尽可能的一次性使用完，利用了数据的局部性特点】
 - 尽可能跨距为1的访问数据（空间局部性）【在访问一个数据时，应该依次的访问数组元素，不要跳着访问，利用了数据的空间局限性】

当我们访问一个内存地址单元时会将同一块的的数据同时从内存读入到Cache,这样如果我们继续访问附近的数据，那它就已经位于Cache中，访问速度就会很快。

对于矩阵乘法，可以通过调整ijk的顺序提高cache命中。并且可以使用分块的思想：L2 Cache大小有限，如果不停地访存很快会把L2 Cache刷满一遍。因此应该让高密度计算中的访存范围集中，使用分块的方法。

自己的总结：我们应该尽量让当前运算的部分优先完全放在register - l1 - l2 - l3 - memory中，并且下次用到的优先完全放在 l1 - l2 - l3 - memory。 并且可以利用SIMD的指令集（下发一个指令可以同时对多个数据做运算，这就是单指令多数据流）。

### 字节对齐、 alignas

字节对齐有以下准则：
 - 结构体变量的首地址能够被其对齐字节数大小所整除。
 - 结构体每个成员相对结构体首地址的偏移都是成员大小的整数倍，如不满足，对前一个成员填充字节以满足。
 - 结构体的总大小为结构体对最大成员大小的整数倍，如不满足，最后填充字节以满足。

alignas用来设置内存中对齐方式。比如可以把结构体的大小按64字节（cache line大小）对齐：
```cpp
struct alignas(64) FeatureValue {
...
};
```

### SIMD与SIMT

### TVM

### TensorRT

### XLA

### LLVM

### GPU redution / prefix sum
