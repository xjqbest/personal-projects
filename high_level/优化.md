

### cache友好

我们可以通过编程来充分利用cache性能，但是我们需要同时考虑数据的组织形式和数据的访问形式，此外，
可以使用分块处理的方式获得空间局部性更好的方法。获得最佳Cache性能是与平台相关的，比如，
Cache的大小，Cache行大小，以及映射策略。比较通用的法则当然是工作集越小越好，访问跨距越小越好。

一段Cache友好代码往往运行速度较快。但我们需要注意以下两点：
 - 尽可能多的重复使用一个数据（时间局限性）【如果我们需要在某个任务多次使用一个数据时，应该尽可能的一次性使用完，利用了数据的局部性特点】
 - 尽可能跨距为1的访问数据（空间局部性）【在访问一个数据时，应该依次的访问数组元素，不要跳着访问，利用了数据的空间局限性】

当我们访问一个内存地址单元时会将同一块的的数据同时从内存读入到Cache,这样如果我们继续访问附近的数据，那它就已经位于Cache中，访问速度就会很快。

对于矩阵乘法，可以通过调整ijk的顺序提高cache命中。并且可以使用分块的思想：L2 Cache大小有限，如果不停地访存很快会把L2 Cache刷满一遍。因此应该让高密度计算中的访存范围集中，使用分块的方法。

自己的总结：我们应该尽量让当前运算的部分优先完全放在register - l1 - l2 - l3 - memory中，并且下次用到的优先完全放在 l1 - l2 - l3 - memory。 并且可以利用SIMD的指令集（下发一个指令可以同时对多个数据做运算，这就是单指令多数据流）。

### 字节对齐、 alignas

字节对齐有以下准则：
 - 结构体变量的首地址能够被其对齐字节数大小所整除。
 - 结构体每个成员相对结构体首地址的偏移都是成员大小的整数倍，如不满足，对前一个成员填充字节以满足。
 - 结构体的总大小为结构体对最大成员大小的整数倍，如不满足，最后填充字节以满足。

alignas用来设置内存中对齐方式。比如可以把结构体的大小按64字节（cache line大小）对齐：
```cpp
struct alignas(64) FeatureValue {
...
};
```

### SIMD与SIMT

SIMD是指同一条指令多个数据。SIMT是同一条指令多个线程。

SIMD：采用一个控制器来控制多个处理单元，同时对一组数据的元素分别执行相同的操作从而实现空间上并行的技术。

SIMT：由一组标量处理单元构成，每个处理单元对应一个硬件线程，所有处理单元共享指令预取/译码模块并接收同一指令，运行其上的线程可以有自己的寄存器、独立的内存访问寻址、执行分支。


为了避免一些高延迟指令引起处理单元流水线停顿，CPU和GPU采取了完全不同的做法：
 - CPU的做法是一方面穷尽所能充分挖掘指令级并行来规避，另一方面通过`多级Cache、分支预测来掩盖访问内存延迟`(提高数据缓存命中率、指令缓存命中率)，万不得已CPU才会切换到别的硬件线程执行。硬件线程数量太多切换太频繁即使有助于整体吞吐却恶化单个线程的延迟对CPU设计来说也是不可接受的，所以我们可以看到Hyperthread的数目一般都比较少。

 - GPU的做法是另外一种思路，大规模数据并行带来`海量的可执行线程`，GPU完全可以`通过切换到别的线程Warp来规避指令延迟带来处理单元的停顿`。这种切换会非常频繁，需要在很短时间完成(比如一个时钟)，所以无论每个线程执行需要的的寄存器堆还是Block之内线程的Shared Memory从一开始就要分配妥当，`切换过程中线程上下文一直驻留，直到线程或者整个Block执行结束才能释放`。所以相比CPU，`GPU的Register非常多，而其处理单元的设计却可以异常简单`。

### TVM

### TensorRT

### XLA

### LLVM

### GPU redution / prefix sum
