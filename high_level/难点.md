

## paddle fleet

#### (1) 数据量大
 
 - 样本数据结构优化。每个slot对应三个vector 改为 每个样本存slot、key的pair。
 
 - shuffle：如何充分shuffle数据（worker本地shuffle + worker间通过rpc shuffle），不丢数据（发数据做流控、收数据增大线程数），数据分布

 - dataset InMemory模式 和 Queue模式，内存装得下就用前者，否则就用后者。

#### (2) 参数量大

 - hash map性能：通常影响它的几个主要的因素是`哈希函数的选择`（尽量减少哈希碰撞）、`哈希冲突`、`内存分配`。哈希冲突的解决可以采用cache友好的线性探测法。内存分配可以采用事先一个内存池作为allocator或者使用tcmalloc或者jemalloc等库。针对不同的场景，可以采用不同的hash表的实现。

 - server端sparse参数分多个shard，由多个线程分别处理，提高并发。

 - pull对key去重、push merge多个batch梯度，缓解热点key的问题。

 - dense参数原本是每个线程独立一份，并且每个batch都pull/push一次，改为多线程共享一份dense参数，并且是单独的异步更新，因为数据量大，对效果影响很小。
 
 - 分层参数服务器（HBM-MEM-SSD），做单机GPU训练。

 
不同的哈希表：
 - dense_hash_map，占用内存较多,而且内存一大块一大块申请的。适合内存充足的情况。二次内部探测处理碰撞，更加cache友好。（unordered_map采用链表的方法解决碰撞）
 - sparse_hash_map，占用的内存较少，适合内存比较紧张的情况。它分成了若干group，对元素的操作都在group内部完成，
 - 还有一些特殊实现的哈希表，比如Cuckoo Hash（布谷鸟哈希），它维护了两个hash table，最大的特点是lookup最坏时间复杂度O(1)。还有Robin Hood hash（罗宾汉哈希）也具有cache friendly的特点，查找不存在的key也能很快。


#### 通用性、易用性

 - embedding layer能够更灵活组网：将pull op化。

 - 强化学习DQN，target网络更新：copy table。

 - 自定义metric计算：提供一些基本操作的类（global sum/mean/avg）或者op。

 - 配置：避免比较多的set_xxx，将配置作为一整个字典传入。


## hippo

同步训练中的数据分配：每个minibatch被分成若干block分配给所有worker，如何尽量提高训练速度。
 - （1）慢节点少分配数据，正常节点多分配数据
 - （2）由于慢节点通常是随机的出现一段时间，可能后面就成为了正常节点，避免它由于中间一段时间成为慢节点后就一直饥饿。
  
因此给每个worker一个权重，同时考虑它的消费block的速度和等待数据的时间。分配时不能简单按照权重成反比来分配，而是采用一个最小堆，贪心的求总时间最短。



## numerous

相对而言，目前支持的业务参数量不大。

数据遇到过磁盘IO瓶颈。并且将原始数据的预处理（特征id化、特征交叉）提前。这两点解决，基本就满足了cpu分布式训练。
