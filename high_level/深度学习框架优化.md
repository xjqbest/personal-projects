
## 训练优化

![image](https://user-images.githubusercontent.com/12492564/150645777-1206de3c-f7c3-4156-bba8-fe863e649179.png)


![image](https://user-images.githubusercontent.com/12492564/150645806-f0c60cf9-9703-4fef-9558-2d1be18ab44e.png)

## 推理优化

推断（Inference）和训练（Training）的不同：
 - 模型固定，可以对计算图进行优化
 - 输入输出大小固定，可以做memory优化
 - 推断（Inference）的batch size要小很多，吞吐降低，没有办法很好地利用GPU
 - 推断（Inference）可以使用低精度的技术，训练的时候因为要保证前后向传播，每次梯度的更新是很微小的，这个时候需要相对较高的精度

优化：
 - tensorrt：将tf等框架的计算图转为tensorrt中，然后在tensorRT中可以针对NVIDIA自家GPU实施优化策略（算子融合、量化、显存复用、多stream并行）
 - xla：tensorflow内置的编译优化工具（算子的融合）
 - tvm：更全面。将不同前端深度学习框架训练的模型，转换为统一的中间语言表示，并对其进行优化，转换为目标硬件上的代码逻辑。

